% Generated by roxygen2 (4.0.1): do not edit by hand
\name{makeTuneControlCMAES}
\alias{TuneControl}
\alias{TuneControlCMAES}
\alias{TuneControlGrid}
\alias{TuneControlIrace}
\alias{TuneControlOptim}
\alias{TuneControlRandom}
\alias{makeTuneControlCMAES}
\alias{makeTuneControlGenSA}
\alias{makeTuneControlGrid}
\alias{makeTuneControlIrace}
\alias{makeTuneControlRandom}
\title{Create control structures for tuning.}
\usage{
makeTuneControlCMAES(same.resampling.instance = TRUE, impute.val = Inf,
  start = NULL, ...)

makeTuneControlGenSA(same.resampling.instance = TRUE, impute.val = Inf,
  start = NULL, ...)

makeTuneControlGrid(same.resampling.instance = TRUE, impute.val = Inf,
  resolution = 10L)

makeTuneControlIrace(impute.val = Inf, n.instances = 100L,
  show.irace.output = FALSE, ...)

makeTuneControlRandom(same.resampling.instance = TRUE, impute.val = Inf,
  maxit = 100L)
}
\arguments{
\item{resolution}{[\code{integer}]\cr
Resolution of the grid for each numeric/integer parameter in \code{par.set}.
For vector parameters, it is the resolution per dimension.
Either pass one resolution for all parameters, or a named vector.
See \code{\link[ParamHelpers]{generateGridDesign}}.
Default is 10.}

\item{n.instances}{[\code{integer(1)}]\cr
Number of random resampling instances for irace, see details.
Default is 100.}

\item{show.irace.output}{[\code{logical(1)}]\cr
Show console output of irace while tuning?
Default is \code{FALSE}.}

\item{same.resampling.instance}{[\code{logical(1)}]\cr
Should the same resampling instance be used for all evaluations to reduce variance?
Default is \code{TRUE}.}

\item{impute.val}{[\code{numeric(1)}]\cr
If something goes wrong during optimization (e.g, the learner crashes),
this value is fed back to the tuner, so the tuning algorithm does not abort.
It is not stored in the optimization path, an NA and a corresponding error message are
logged instead.
Note that this value is later multiplied by -1 for maximization measures internally, so you
need to enter a larger positive value for maximization here as well.
Default is the worst obtainable value of the performance measure you optimize for when
you aggregate by mean value, or \code{Inf} instead.}

\item{start}{[\code{numeric}]\cr
Named list of initial parameter values.}

\item{...}{[any]\cr
Further control parameters passed to the \code{control} argument of \code{\link[stats]{optim}},
the \code{control} argument of \code{\link[cmaes]{cma_es}}, \code{tunerConfig}
argument of \code{\link[irace]{irace}}.}

\item{maxit}{[\code{integer(1)}]\cr
Number of iterations for random search.
Default is 100.}
}
\value{
[\code{\link{TuneControl}}]. The specific subclass is one of
  \code{\link{TuneControlGrid}}, \code{\link{TuneControlRandom}}, \code{\link{TuneControlOptim}},
  \code{\link{TuneControlCMAES}}, \code{\link{TuneControlIrace}}.
}
\description{
The following tuners are available:
\describe{
  \item{makeTuneControlGrid}{Grid search. All kinds of parameter types can be handled,
    but you have discretize them yourself by always using
    \code{\link[ParamHelpers]{makeDiscreteParam}} in the \code{par.set}
    passed to \code{\link{tuneParams}}.}
  \item{makeTuneControlRandom}{Random search. All kinds of parameter types can be handled.}
  \item{makeTuneControlOptim}{Tuning with \code{\link[stats]{optim}}.
    Can handle numeric(vector) and integer(vector) hyperparameters.
    For integers the internally proposed numeric values are automatically rounded.}
  \item{makeTuneControlCMAES}{CMA Evolution Strategy with method \code{\link[cmaes]{cma_es}}.
    Can handle numeric(vector) and integer(vector) hyperparameters.
    For integers the internally proposed numeric values are automatically rounded.
    The sigma variance parameter is initialized to 1/4 of the span of box-constraints per
    parameter dimension.}
  \item{makeTuneControlIrace}{Tuning with iterated F-Racing with method \code{\link[irace]{irace}}.
    All kinds of parameter types can be handled. We return the best of the final elite
    candidates found by irace in the last race. Its estimated performance is the mean of all
    evaluations ever done for that candidate.}
}

Dependent parameters can currently only be handled by random search and irace.

Some notes on irace: For resampling you have to pass a \code{\link{ResampleDesc}},
not a \code{\link{ResampleInstance}}.
The resampling strategy is randomly instantiated \code{n.instances} times and
these are the instances in the sense of irace (\code{instances} element of \code{tunerConfig}
in \code{\link[irace]{irace}}). Also note that irace will always
store its tuning results in a file on disk, see the package documentation for details on this
and how to change the file path.
}
\seealso{
Other tune: \code{\link{ModelMultiplexer}},
  \code{\link{makeModelMultiplexer}};
  \code{\link{getTuneResult}};
  \code{\link{makeModelMultiplexerParamSet}};
  \code{\link{makeTuneWrapper}}; \code{\link{tuneParams}};
  \code{\link{tuneThreshold}}
}

